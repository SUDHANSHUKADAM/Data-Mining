{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOPfYlzNAojJsKPyicD6SKn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SUDHANSHUKADAM/Data-Mining/blob/main/improve.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# data analysis and wrangling\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random as rnd\n",
        "\n",
        "# visualization\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# machine learning\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC, LinearSVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.linear_model import Perceptron\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier"
      ],
      "metadata": {
        "id": "ppmJD7OSZ_fR"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data input\n"
      ],
      "metadata": {
        "id": "lAelhNMcnZDW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Read the training dataset\n",
        "train_data = pd.read_csv('train.csv')\n",
        "\n",
        "# Read the test dataset\n",
        "test_data = pd.read_csv('test.csv')\n",
        "\n",
        "# Display basic information about the training dataset\n",
        "print(\"Training Dataset Info:\")\n",
        "print(train_data.info())\n",
        "\n",
        "# Display the first few rows of the training dataset\n",
        "print(\"\\nFirst few rows of the training dataset:\")\n",
        "print(train_data.head())\n",
        "\n",
        "# Display basic information about the test dataset\n",
        "print(\"\\nTest Dataset Info:\")\n",
        "print(test_data.info())\n",
        "\n",
        "# Display the first few rows of the test dataset\n",
        "print(\"\\nFirst few rows of the test dataset:\")\n",
        "print(test_data.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DiYz8w1pbt-w",
        "outputId": "1ad6d248-ce42-45bc-9cc8-cd2e3628d4ec"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Dataset Info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 891 entries, 0 to 890\n",
            "Data columns (total 12 columns):\n",
            " #   Column       Non-Null Count  Dtype  \n",
            "---  ------       --------------  -----  \n",
            " 0   PassengerId  891 non-null    int64  \n",
            " 1   Survived     891 non-null    int64  \n",
            " 2   Pclass       891 non-null    int64  \n",
            " 3   Name         891 non-null    object \n",
            " 4   Sex          891 non-null    object \n",
            " 5   Age          714 non-null    float64\n",
            " 6   SibSp        891 non-null    int64  \n",
            " 7   Parch        891 non-null    int64  \n",
            " 8   Ticket       891 non-null    object \n",
            " 9   Fare         891 non-null    float64\n",
            " 10  Cabin        204 non-null    object \n",
            " 11  Embarked     889 non-null    object \n",
            "dtypes: float64(2), int64(5), object(5)\n",
            "memory usage: 83.7+ KB\n",
            "None\n",
            "\n",
            "First few rows of the training dataset:\n",
            "   PassengerId  Survived  Pclass  \\\n",
            "0            1         0       3   \n",
            "1            2         1       1   \n",
            "2            3         1       3   \n",
            "3            4         1       1   \n",
            "4            5         0       3   \n",
            "\n",
            "                                                Name     Sex   Age  SibSp  \\\n",
            "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
            "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
            "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
            "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
            "4                           Allen, Mr. William Henry    male  35.0      0   \n",
            "\n",
            "   Parch            Ticket     Fare Cabin Embarked  \n",
            "0      0         A/5 21171   7.2500   NaN        S  \n",
            "1      0          PC 17599  71.2833   C85        C  \n",
            "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
            "3      0            113803  53.1000  C123        S  \n",
            "4      0            373450   8.0500   NaN        S  \n",
            "\n",
            "Test Dataset Info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 418 entries, 0 to 417\n",
            "Data columns (total 11 columns):\n",
            " #   Column       Non-Null Count  Dtype  \n",
            "---  ------       --------------  -----  \n",
            " 0   PassengerId  418 non-null    int64  \n",
            " 1   Pclass       418 non-null    int64  \n",
            " 2   Name         418 non-null    object \n",
            " 3   Sex          418 non-null    object \n",
            " 4   Age          332 non-null    float64\n",
            " 5   SibSp        418 non-null    int64  \n",
            " 6   Parch        418 non-null    int64  \n",
            " 7   Ticket       418 non-null    object \n",
            " 8   Fare         417 non-null    float64\n",
            " 9   Cabin        91 non-null     object \n",
            " 10  Embarked     418 non-null    object \n",
            "dtypes: float64(2), int64(4), object(5)\n",
            "memory usage: 36.0+ KB\n",
            "None\n",
            "\n",
            "First few rows of the test dataset:\n",
            "   PassengerId  Pclass                                          Name     Sex  \\\n",
            "0          892       3                              Kelly, Mr. James    male   \n",
            "1          893       3              Wilkes, Mrs. James (Ellen Needs)  female   \n",
            "2          894       2                     Myles, Mr. Thomas Francis    male   \n",
            "3          895       3                              Wirz, Mr. Albert    male   \n",
            "4          896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female   \n",
            "\n",
            "    Age  SibSp  Parch   Ticket     Fare Cabin Embarked  \n",
            "0  34.5      0      0   330911   7.8292   NaN        Q  \n",
            "1  47.0      1      0   363272   7.0000   NaN        S  \n",
            "2  62.0      0      0   240276   9.6875   NaN        Q  \n",
            "3  27.0      0      0   315154   8.6625   NaN        S  \n",
            "4  22.0      1      1  3101298  12.2875   NaN        S  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Removing Title from name"
      ],
      "metadata": {
        "id": "TQRsijM7ndWm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_title(name):\n",
        "    title_search = re.search(' ([A-Za-z]+)\\.', name)\n",
        "    if title_search:\n",
        "        return title_search.group(1)\n",
        "    return \"\"\n",
        "\n",
        "# Extract titles from names\n",
        "train_data['Title'] = train_data['Name'].apply(get_title)\n",
        "test_data['Title'] = test_data['Name'].apply(get_title)\n",
        "\n",
        "# Print unique titles\n",
        "print(\"Unique titles in training data:\", train_data['Title'].unique())\n",
        "print(\"Unique titles in test data:\", test_data['Title'].unique())\n",
        "\n",
        "# Function to map titles to numbers\n",
        "def map_title(title):\n",
        "    title_mapping = {\n",
        "        \"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4,\n",
        "        \"Dr\": 5, \"Rev\": 5, \"Col\": 5, \"Major\": 5, \"Mlle\": 2,\n",
        "        \"Countess\": 5, \"Ms\": 2, \"Lady\": 5, \"Jonkheer\": 5,\n",
        "        \"Don\": 5, \"Dona\": 5, \"Mme\": 3, \"Capt\": 5, \"Sir\": 5\n",
        "    }\n",
        "    return title_mapping.get(title, 5)  # 5 for any rare title\n",
        "\n",
        "# Apply title mapping directly to the 'Title' column\n",
        "train_data['Title'] = train_data['Title'].apply(map_title)\n",
        "test_data['Title'] = test_data['Title'].apply(map_title)\n",
        "\n",
        "# Display the first few rows to verify\n",
        "print(\"\\nFirst few rows of training data with updated Title column:\")\n",
        "print(train_data[['Name', 'Title']].head())\n",
        "\n",
        "print(\"\\nFirst few rows of test data with updated Title column:\")\n",
        "print(test_data[['Name', 'Title']].head())\n",
        "\n",
        "# Check the distribution of titles in training data\n",
        "print(\"\\nDistribution of titles in training data:\")\n",
        "print(train_data['Title'].value_counts().sort_index())\n",
        "\n",
        "# Check the distribution of titles in test data\n",
        "print(\"\\nDistribution of titles in test data:\")\n",
        "print(test_data['Title'].value_counts().sort_index())\n",
        "\n",
        "# Save the updated datasets\n",
        "train_data.to_csv('train_updated.csv', index=False)\n",
        "test_data.to_csv('test_updated.csv', index=False)\n",
        "\n",
        "print(\"\\nUpdated datasets have been saved as 'train_updated.csv' and 'test_updated.csv'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VAa9rByzdCAN",
        "outputId": "6f50508f-4565-4f55-e1a6-49f8fb19f553"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique titles in training data: ['Mr' 'Mrs' 'Miss' 'Master' 'Don' 'Rev' 'Dr' 'Mme' 'Ms' 'Major' 'Lady'\n",
            " 'Sir' 'Mlle' 'Col' 'Capt' 'Countess' 'Jonkheer']\n",
            "Unique titles in test data: ['Mr' 'Mrs' 'Miss' 'Master' 'Ms' 'Col' 'Rev' 'Dr' 'Dona']\n",
            "\n",
            "First few rows of training data with updated Title column:\n",
            "                                                Name  Title\n",
            "0                            Braund, Mr. Owen Harris      1\n",
            "1  Cumings, Mrs. John Bradley (Florence Briggs Th...      3\n",
            "2                             Heikkinen, Miss. Laina      2\n",
            "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)      3\n",
            "4                           Allen, Mr. William Henry      1\n",
            "\n",
            "First few rows of test data with updated Title column:\n",
            "                                           Name  Title\n",
            "0                              Kelly, Mr. James      1\n",
            "1              Wilkes, Mrs. James (Ellen Needs)      3\n",
            "2                     Myles, Mr. Thomas Francis      1\n",
            "3                              Wirz, Mr. Albert      1\n",
            "4  Hirvonen, Mrs. Alexander (Helga E Lindqvist)      3\n",
            "\n",
            "Distribution of titles in training data:\n",
            "Title\n",
            "1    517\n",
            "2    185\n",
            "3    126\n",
            "4     40\n",
            "5     23\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Distribution of titles in test data:\n",
            "Title\n",
            "1    240\n",
            "2     79\n",
            "3     72\n",
            "4     21\n",
            "5      6\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Updated datasets have been saved as 'train_updated.csv' and 'test_updated.csv'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Changing sex to numeric value"
      ],
      "metadata": {
        "id": "hk-RiX_XniO9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to convert sex to numeric\n",
        "def sex_to_numeric(sex):\n",
        "    return 1 if sex == 'male' else 0\n",
        "\n",
        "# Apply the conversion to both datasets and replace the 'Sex' column\n",
        "train_data['Sex'] = train_data['Sex'].apply(sex_to_numeric)\n",
        "test_data['Sex'] = test_data['Sex'].apply(sex_to_numeric)\n",
        "\n",
        "# Display the first few rows to verify\n",
        "print(\"First few rows of training data with updated Sex column:\")\n",
        "print(train_data[['PassengerId', 'Sex', 'Age', 'Survived']].head())\n",
        "\n",
        "print(\"\\nFirst few rows of test data with updated Sex column:\")\n",
        "print(test_data[['PassengerId', 'Sex', 'Age']].head())\n",
        "\n",
        "# Check the distribution of Sex in training data\n",
        "print(\"\\nDistribution of Sex in training data:\")\n",
        "print(train_data['Sex'].value_counts())\n",
        "\n",
        "# Check the distribution of Sex in test data\n",
        "print(\"\\nDistribution of Sex in test data:\")\n",
        "print(test_data['Sex'].value_counts())\n",
        "\n",
        "# Verify the mapping\n",
        "print(\"\\nUnique values in Sex column (train):\", train_data['Sex'].unique())\n",
        "print(\"Unique values in Sex column (test):\", test_data['Sex'].unique())\n",
        "\n",
        "# Save the updated datasets\n",
        "train_data.to_csv('train_updated.csv', index=False)\n",
        "test_data.to_csv('test_updated.csv', index=False)\n",
        "\n",
        "print(\"\\nUpdated datasets have been saved as 'train_updated.csv' and 'test_updated.csv'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KmChquL5dJw_",
        "outputId": "99197867-6b50-4774-907e-d9ad50857cb3"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First few rows of training data with updated Sex column:\n",
            "   PassengerId  Sex   Age  Survived\n",
            "0            1    1  22.0         0\n",
            "1            2    0  38.0         1\n",
            "2            3    0  26.0         1\n",
            "3            4    0  35.0         1\n",
            "4            5    1  35.0         0\n",
            "\n",
            "First few rows of test data with updated Sex column:\n",
            "   PassengerId  Sex   Age\n",
            "0          892    1  34.5\n",
            "1          893    0  47.0\n",
            "2          894    1  62.0\n",
            "3          895    1  27.0\n",
            "4          896    0  22.0\n",
            "\n",
            "Distribution of Sex in training data:\n",
            "Sex\n",
            "1    577\n",
            "0    314\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Distribution of Sex in test data:\n",
            "Sex\n",
            "1    266\n",
            "0    152\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Unique values in Sex column (train): [1 0]\n",
            "Unique values in Sex column (test): [1 0]\n",
            "\n",
            "Updated datasets have been saved as 'train_updated.csv' and 'test_updated.csv'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Making a new column Familysize"
      ],
      "metadata": {
        "id": "fjWW34d6nmUF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_family_size(row):\n",
        "    return row['SibSp'] + row['Parch'] + 1  # Adding 1 for the passenger themselves\n",
        "\n",
        "# Apply the function to create the FamilySize column for both datasets\n",
        "train_data['FamilySize'] = train_data.apply(calculate_family_size, axis=1)\n",
        "test_data['FamilySize'] = test_data.apply(calculate_family_size, axis=1)\n",
        "\n",
        "# Display the first few rows to verify\n",
        "print(\"First few rows of training data with new FamilySize column:\")\n",
        "print(train_data[['PassengerId', 'SibSp', 'Parch', 'FamilySize']].head())\n",
        "\n",
        "print(\"\\nFirst few rows of test data with new FamilySize column:\")\n",
        "print(test_data[['PassengerId', 'SibSp', 'Parch', 'FamilySize']].head())\n",
        "\n",
        "# Check the distribution of FamilySize in training data\n",
        "print(\"\\nDistribution of FamilySize in training data:\")\n",
        "print(train_data['FamilySize'].value_counts().sort_index())\n",
        "\n",
        "# Check the distribution of FamilySize in test data\n",
        "print(\"\\nDistribution of FamilySize in test data:\")\n",
        "print(test_data['FamilySize'].value_counts().sort_index())\n",
        "\n",
        "# Save the updated datasets\n",
        "train_data.to_csv('train_updated.csv', index=False)\n",
        "test_data.to_csv('test_updated.csv', index=False)\n",
        "\n",
        "print(\"\\nUpdated datasets have been saved as 'train_updated.csv' and 'test_updated.csv'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JzvVLbE4eHOX",
        "outputId": "3725fbf9-e718-4cb9-8c39-2f5634535b50"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First few rows of training data with new FamilySize column:\n",
            "   PassengerId  SibSp  Parch  FamilySize\n",
            "0            1      1      0           2\n",
            "1            2      1      0           2\n",
            "2            3      0      0           1\n",
            "3            4      1      0           2\n",
            "4            5      0      0           1\n",
            "\n",
            "First few rows of test data with new FamilySize column:\n",
            "   PassengerId  SibSp  Parch  FamilySize\n",
            "0          892      0      0           1\n",
            "1          893      1      0           2\n",
            "2          894      0      0           1\n",
            "3          895      0      0           1\n",
            "4          896      1      1           3\n",
            "\n",
            "Distribution of FamilySize in training data:\n",
            "FamilySize\n",
            "1     537\n",
            "2     161\n",
            "3     102\n",
            "4      29\n",
            "5      15\n",
            "6      22\n",
            "7      12\n",
            "8       6\n",
            "11      7\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Distribution of FamilySize in test data:\n",
            "FamilySize\n",
            "1     253\n",
            "2      74\n",
            "3      57\n",
            "4      14\n",
            "5       7\n",
            "6       3\n",
            "7       4\n",
            "8       2\n",
            "11      4\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Updated datasets have been saved as 'train_updated.csv' and 'test_updated.csv'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Removing column cabin and ticket"
      ],
      "metadata": {
        "id": "b7LKboaYntrm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Display original column names\n",
        "print(\"Original columns in training data:\", train_data.columns.tolist())\n",
        "print(\"Original columns in test data:\", test_data.columns.tolist())\n",
        "\n",
        "# Remove 'Cabin' and 'Ticket' columns from both datasets\n",
        "columns_to_drop = ['Cabin', 'Ticket']\n",
        "train_data = train_data.drop(columns=columns_to_drop)\n",
        "test_data = test_data.drop(columns=columns_to_drop)\n",
        "\n",
        "# Display new column names to verify removal\n",
        "print(\"\\nColumns in training data after removal:\", train_data.columns.tolist())\n",
        "print(\"Columns in test data after removal:\", test_data.columns.tolist())\n",
        "\n",
        "# Display the first few rows to verify\n",
        "print(\"\\nFirst few rows of training data after column removal:\")\n",
        "print(train_data.head())\n",
        "\n",
        "print(\"\\nFirst few rows of test data after column removal:\")\n",
        "print(test_data.head())\n",
        "\n",
        "# Save the updated datasets\n",
        "train_data.to_csv('train_updated.csv', index=False)\n",
        "test_data.to_csv('test_updated.csv', index=False)\n",
        "\n",
        "print(\"\\nUpdated datasets have been saved as 'train_updated.csv' and 'test_updated.csv'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kn51g0fFe7xB",
        "outputId": "14692f5c-4e67-4964-8fc3-e81cd6add5c7"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original columns in training data: ['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked', 'Title', 'FamilySize']\n",
            "Original columns in test data: ['PassengerId', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked', 'Title', 'FamilySize']\n",
            "\n",
            "Columns in training data after removal: ['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked', 'Title', 'FamilySize']\n",
            "Columns in test data after removal: ['PassengerId', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked', 'Title', 'FamilySize']\n",
            "\n",
            "First few rows of training data after column removal:\n",
            "   PassengerId  Survived  Pclass  \\\n",
            "0            1         0       3   \n",
            "1            2         1       1   \n",
            "2            3         1       3   \n",
            "3            4         1       1   \n",
            "4            5         0       3   \n",
            "\n",
            "                                                Name  Sex   Age  SibSp  Parch  \\\n",
            "0                            Braund, Mr. Owen Harris    1  22.0      1      0   \n",
            "1  Cumings, Mrs. John Bradley (Florence Briggs Th...    0  38.0      1      0   \n",
            "2                             Heikkinen, Miss. Laina    0  26.0      0      0   \n",
            "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)    0  35.0      1      0   \n",
            "4                           Allen, Mr. William Henry    1  35.0      0      0   \n",
            "\n",
            "      Fare Embarked  Title  FamilySize  \n",
            "0   7.2500        S      1           2  \n",
            "1  71.2833        C      3           2  \n",
            "2   7.9250        S      2           1  \n",
            "3  53.1000        S      3           2  \n",
            "4   8.0500        S      1           1  \n",
            "\n",
            "First few rows of test data after column removal:\n",
            "   PassengerId  Pclass                                          Name  Sex  \\\n",
            "0          892       3                              Kelly, Mr. James    1   \n",
            "1          893       3              Wilkes, Mrs. James (Ellen Needs)    0   \n",
            "2          894       2                     Myles, Mr. Thomas Francis    1   \n",
            "3          895       3                              Wirz, Mr. Albert    1   \n",
            "4          896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)    0   \n",
            "\n",
            "    Age  SibSp  Parch     Fare Embarked  Title  FamilySize  \n",
            "0  34.5      0      0   7.8292        Q      1           1  \n",
            "1  47.0      1      0   7.0000        S      3           2  \n",
            "2  62.0      0      0   9.6875        Q      1           1  \n",
            "3  27.0      0      0   8.6625        S      1           1  \n",
            "4  22.0      1      1  12.2875        S      3           3  \n",
            "\n",
            "Updated datasets have been saved as 'train_updated.csv' and 'test_updated.csv'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Filling null values in age column"
      ],
      "metadata": {
        "id": "5qeoXLIAn8Go"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the number of null values in the Age column before filling\n",
        "print(\"Number of null values in Age column (train) before:\", train_data['Age'].isnull().sum())\n",
        "print(\"Number of null values in Age column (test) before:\", test_data['Age'].isnull().sum())\n",
        "\n",
        "# Fill null values in the Age column with 29\n",
        "train_data['Age'] = train_data['Age'].fillna(29)\n",
        "test_data['Age'] = test_data['Age'].fillna(29)\n",
        "\n",
        "# Display the number of null values in the Age column after filling\n",
        "print(\"\\nNumber of null values in Age column (train) after:\", train_data['Age'].isnull().sum())\n",
        "print(\"Number of null values in Age column (test) after:\", test_data['Age'].isnull().sum())\n",
        "\n",
        "# Display the first few rows to verify changes\n",
        "print(\"\\nFirst few rows of training data after filling Age:\")\n",
        "print(train_data[['PassengerId', 'Age']].head())\n",
        "\n",
        "print(\"\\nFirst few rows of test data after filling Age:\")\n",
        "print(test_data[['PassengerId', 'Age']].head())\n",
        "\n",
        "# Save the updated datasets\n",
        "train_data.to_csv('train_updated.csv', index=False)\n",
        "test_data.to_csv('test_updated.csv', index=False)\n",
        "\n",
        "print(\"\\nUpdated datasets have been saved as 'train_updated.csv' and 'test_updated.csv'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UOfN-StIfIEY",
        "outputId": "daa1e166-31ac-4736-eaa6-1510e00e11e1"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of null values in Age column (train) before: 177\n",
            "Number of null values in Age column (test) before: 86\n",
            "\n",
            "Number of null values in Age column (train) after: 0\n",
            "Number of null values in Age column (test) after: 0\n",
            "\n",
            "First few rows of training data after filling Age:\n",
            "   PassengerId   Age\n",
            "0            1  22.0\n",
            "1            2  38.0\n",
            "2            3  26.0\n",
            "3            4  35.0\n",
            "4            5  35.0\n",
            "\n",
            "First few rows of test data after filling Age:\n",
            "   PassengerId   Age\n",
            "0          892  34.5\n",
            "1          893  47.0\n",
            "2          894  62.0\n",
            "3          895  27.0\n",
            "4          896  22.0\n",
            "\n",
            "Updated datasets have been saved as 'train_updated.csv' and 'test_updated.csv'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Categorising age"
      ],
      "metadata": {
        "id": "zmXcwbJCn-Dm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to categorize age\n",
        "def categorize_age(age):\n",
        "    if 0 <= age <= 25:\n",
        "        return 1\n",
        "    elif 26 <= age <= 50:\n",
        "        return 2\n",
        "    elif 51 <= age <= 75:\n",
        "        return 3\n",
        "    else:\n",
        "        return 4\n",
        "\n",
        "# Apply the categorization to both datasets, replacing the 'Age' column\n",
        "train_data['Age'] = train_data['Age'].apply(categorize_age)\n",
        "test_data['Age'] = test_data['Age'].apply(categorize_age)\n",
        "\n",
        "# Display the first few rows to verify changes\n",
        "print(\"First few rows of training data with categorized Age:\")\n",
        "print(train_data[['PassengerId', 'Age']].head())\n",
        "\n",
        "print(\"\\nFirst few rows of test data with categorized Age:\")\n",
        "print(test_data[['PassengerId', 'Age']].head())\n",
        "\n",
        "# Check the distribution of Age categories in training data\n",
        "print(\"\\nDistribution of Age categories in training data:\")\n",
        "print(train_data['Age'].value_counts().sort_index())\n",
        "\n",
        "# Check the distribution of Age categories in test data\n",
        "print(\"\\nDistribution of Age categories in test data:\")\n",
        "print(test_data['Age'].value_counts().sort_index())\n",
        "\n",
        "# Save the updated datasets\n",
        "train_data.to_csv('train_updated.csv', index=False)\n",
        "test_data.to_csv('test_updated.csv', index=False)\n",
        "\n",
        "print(\"\\nUpdated datasets have been saved as 'train_updated.csv' and 'test_updated.csv'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i9s6iiWxgQCp",
        "outputId": "f2c3fc03-5bf5-4984-d557-b9ce36c27b4a"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First few rows of training data with categorized Age:\n",
            "   PassengerId  Age\n",
            "0            1    1\n",
            "1            2    2\n",
            "2            3    2\n",
            "3            4    2\n",
            "4            5    2\n",
            "\n",
            "First few rows of test data with categorized Age:\n",
            "   PassengerId  Age\n",
            "0          892    2\n",
            "1          893    2\n",
            "2          894    3\n",
            "3          895    2\n",
            "4          896    1\n",
            "\n",
            "Distribution of Age categories in training data:\n",
            "Age\n",
            "1    301\n",
            "2    526\n",
            "3     63\n",
            "4      1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Distribution of Age categories in test data:\n",
            "Age\n",
            "1    142\n",
            "2    245\n",
            "3     30\n",
            "4      1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Updated datasets have been saved as 'train_updated.csv' and 'test_updated.csv'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Removing fare column"
      ],
      "metadata": {
        "id": "29D-iZCEoDn3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Display original column names\n",
        "print(\"Original columns in training data:\", train_data.columns.tolist())\n",
        "print(\"Original columns in test data:\", test_data.columns.tolist())\n",
        "\n",
        "# Drop the 'Fare' column from both datasets\n",
        "train_data = train_data.drop('Fare', axis=1)\n",
        "test_data = test_data.drop('Fare', axis=1)\n",
        "\n",
        "# Display new column names to verify removal\n",
        "print(\"\\nColumns in training data after removal:\", train_data.columns.tolist())\n",
        "print(\"Columns in test data after removal:\", test_data.columns.tolist())\n",
        "\n",
        "# Display the first few rows to verify\n",
        "print(\"\\nFirst few rows of training data after column removal:\")\n",
        "print(train_data.head())\n",
        "\n",
        "print(\"\\nFirst few rows of test data after column removal:\")\n",
        "print(test_data.head())\n",
        "\n",
        "# Save the updated datasets\n",
        "train_data.to_csv('train_updated.csv', index=False)\n",
        "test_data.to_csv('test_updated.csv', index=False)\n",
        "\n",
        "print(\"\\nUpdated datasets have been saved as 'train_updated.csv' and 'test_updated.csv'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nx5OZK_hh5KX",
        "outputId": "42ceca32-9e80-4243-ce5e-0da53d47144f"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original columns in training data: ['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked', 'Title', 'FamilySize']\n",
            "Original columns in test data: ['PassengerId', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked', 'Title', 'FamilySize']\n",
            "\n",
            "Columns in training data after removal: ['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch', 'Embarked', 'Title', 'FamilySize']\n",
            "Columns in test data after removal: ['PassengerId', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch', 'Embarked', 'Title', 'FamilySize']\n",
            "\n",
            "First few rows of training data after column removal:\n",
            "   PassengerId  Survived  Pclass  \\\n",
            "0            1         0       3   \n",
            "1            2         1       1   \n",
            "2            3         1       3   \n",
            "3            4         1       1   \n",
            "4            5         0       3   \n",
            "\n",
            "                                                Name  Sex  Age  SibSp  Parch  \\\n",
            "0                            Braund, Mr. Owen Harris    1    1      1      0   \n",
            "1  Cumings, Mrs. John Bradley (Florence Briggs Th...    0    2      1      0   \n",
            "2                             Heikkinen, Miss. Laina    0    2      0      0   \n",
            "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)    0    2      1      0   \n",
            "4                           Allen, Mr. William Henry    1    2      0      0   \n",
            "\n",
            "  Embarked  Title  FamilySize  \n",
            "0        S      1           2  \n",
            "1        C      3           2  \n",
            "2        S      2           1  \n",
            "3        S      3           2  \n",
            "4        S      1           1  \n",
            "\n",
            "First few rows of test data after column removal:\n",
            "   PassengerId  Pclass                                          Name  Sex  \\\n",
            "0          892       3                              Kelly, Mr. James    1   \n",
            "1          893       3              Wilkes, Mrs. James (Ellen Needs)    0   \n",
            "2          894       2                     Myles, Mr. Thomas Francis    1   \n",
            "3          895       3                              Wirz, Mr. Albert    1   \n",
            "4          896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)    0   \n",
            "\n",
            "   Age  SibSp  Parch Embarked  Title  FamilySize  \n",
            "0    2      0      0        Q      1           1  \n",
            "1    2      1      0        S      3           2  \n",
            "2    3      0      0        Q      1           1  \n",
            "3    2      0      0        S      1           1  \n",
            "4    1      1      1        S      3           3  \n",
            "\n",
            "Updated datasets have been saved as 'train_updated.csv' and 'test_updated.csv'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dropping columns that are not required"
      ],
      "metadata": {
        "id": "-q8vLJeUoH_d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Display original column names\n",
        "print(\"Original columns in training data:\", train_data.columns.tolist())\n",
        "print(\"Original columns in test data:\", test_data.columns.tolist())\n",
        "\n",
        "# List of columns to drop\n",
        "columns_to_drop = ['Fare', 'SibSp', 'Parch', 'TitleNum', 'AgeCategory']\n",
        "\n",
        "# Drop the specified columns from both datasets\n",
        "train_data = train_data.drop(columns=columns_to_drop, errors='ignore')\n",
        "test_data = test_data.drop(columns=columns_to_drop, errors='ignore')\n",
        "\n",
        "# Display new column names to verify removal\n",
        "print(\"\\nColumns in training data after removal:\", train_data.columns.tolist())\n",
        "print(\"Columns in test data after removal:\", test_data.columns.tolist())\n",
        "\n",
        "# Display the first few rows to verify\n",
        "print(\"\\nFirst few rows of training data after column removal:\")\n",
        "print(train_data.head())\n",
        "\n",
        "print(\"\\nFirst few rows of test data after column removal:\")\n",
        "print(test_data.head())\n",
        "\n",
        "# Save the updated datasets\n",
        "train_data.to_csv('train_updated.csv', index=False)\n",
        "test_data.to_csv('test_updated.csv', index=False)\n",
        "\n",
        "print(\"\\nUpdated datasets have been saved as 'train_updated.csv' and 'test_updated.csv'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gpdykDnAiPqg",
        "outputId": "2e1375bd-d66c-42ef-e5fd-70a5b352dc36"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original columns in training data: ['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch', 'Embarked', 'Title', 'FamilySize']\n",
            "Original columns in test data: ['PassengerId', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch', 'Embarked', 'Title', 'FamilySize']\n",
            "\n",
            "Columns in training data after removal: ['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'Embarked', 'Title', 'FamilySize']\n",
            "Columns in test data after removal: ['PassengerId', 'Pclass', 'Name', 'Sex', 'Age', 'Embarked', 'Title', 'FamilySize']\n",
            "\n",
            "First few rows of training data after column removal:\n",
            "   PassengerId  Survived  Pclass  \\\n",
            "0            1         0       3   \n",
            "1            2         1       1   \n",
            "2            3         1       3   \n",
            "3            4         1       1   \n",
            "4            5         0       3   \n",
            "\n",
            "                                                Name  Sex  Age Embarked  \\\n",
            "0                            Braund, Mr. Owen Harris    1    1        S   \n",
            "1  Cumings, Mrs. John Bradley (Florence Briggs Th...    0    2        C   \n",
            "2                             Heikkinen, Miss. Laina    0    2        S   \n",
            "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)    0    2        S   \n",
            "4                           Allen, Mr. William Henry    1    2        S   \n",
            "\n",
            "   Title  FamilySize  \n",
            "0      1           2  \n",
            "1      3           2  \n",
            "2      2           1  \n",
            "3      3           2  \n",
            "4      1           1  \n",
            "\n",
            "First few rows of test data after column removal:\n",
            "   PassengerId  Pclass                                          Name  Sex  \\\n",
            "0          892       3                              Kelly, Mr. James    1   \n",
            "1          893       3              Wilkes, Mrs. James (Ellen Needs)    0   \n",
            "2          894       2                     Myles, Mr. Thomas Francis    1   \n",
            "3          895       3                              Wirz, Mr. Albert    1   \n",
            "4          896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)    0   \n",
            "\n",
            "   Age Embarked  Title  FamilySize  \n",
            "0    2        Q      1           1  \n",
            "1    2        S      3           2  \n",
            "2    3        Q      1           1  \n",
            "3    2        S      1           1  \n",
            "4    1        S      3           3  \n",
            "\n",
            "Updated datasets have been saved as 'train_updated.csv' and 'test_updated.csv'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Drop Name Column"
      ],
      "metadata": {
        "id": "33izUTGnoXYV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Display original column names\n",
        "print(\"Original columns in training data:\", train_data.columns.tolist())\n",
        "print(\"Original columns in test data:\", test_data.columns.tolist())\n",
        "\n",
        "# Drop the 'Name' column from both datasets\n",
        "train_data = train_data.drop(columns=['Name'])\n",
        "test_data = test_data.drop(columns=['Name'])\n",
        "\n",
        "# Display new column names to verify removal\n",
        "print(\"\\nColumns in training data after removal:\", train_data.columns.tolist())\n",
        "print(\"Columns in test data after removal:\", test_data.columns.tolist())\n",
        "\n",
        "# Display the first few rows to verify\n",
        "print(\"\\nFirst few rows of training data after column removal:\")\n",
        "print(train_data.head())\n",
        "\n",
        "print(\"\\nFirst few rows of test data after column removal:\")\n",
        "print(test_data.head())\n",
        "\n",
        "# Save the updated datasets\n",
        "train_data.to_csv('train_updated.csv', index=False)\n",
        "test_data.to_csv('test_updated.csv', index=False)\n",
        "\n",
        "print(\"\\nUpdated datasets have been saved as 'train_updated.csv' and 'test_updated.csv'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iaGCbNxGim5e",
        "outputId": "179ddae7-9a66-4d08-c4fa-6d9486f0ee95"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original columns in training data: ['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'Embarked', 'Title', 'FamilySize']\n",
            "Original columns in test data: ['PassengerId', 'Pclass', 'Name', 'Sex', 'Age', 'Embarked', 'Title', 'FamilySize']\n",
            "\n",
            "Columns in training data after removal: ['PassengerId', 'Survived', 'Pclass', 'Sex', 'Age', 'Embarked', 'Title', 'FamilySize']\n",
            "Columns in test data after removal: ['PassengerId', 'Pclass', 'Sex', 'Age', 'Embarked', 'Title', 'FamilySize']\n",
            "\n",
            "First few rows of training data after column removal:\n",
            "   PassengerId  Survived  Pclass  Sex  Age Embarked  Title  FamilySize\n",
            "0            1         0       3    1    1        S      1           2\n",
            "1            2         1       1    0    2        C      3           2\n",
            "2            3         1       3    0    2        S      2           1\n",
            "3            4         1       1    0    2        S      3           2\n",
            "4            5         0       3    1    2        S      1           1\n",
            "\n",
            "First few rows of test data after column removal:\n",
            "   PassengerId  Pclass  Sex  Age Embarked  Title  FamilySize\n",
            "0          892       3    1    2        Q      1           1\n",
            "1          893       3    0    2        S      3           2\n",
            "2          894       2    1    3        Q      1           1\n",
            "3          895       3    1    2        S      1           1\n",
            "4          896       3    0    1        S      3           3\n",
            "\n",
            "Updated datasets have been saved as 'train_updated.csv' and 'test_updated.csv'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Converting embarked column to numeric values"
      ],
      "metadata": {
        "id": "cM8fLjSbobud"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def map_embarked(value):\n",
        "    mapping = {'S': 1, 'Q': 2, 'C': 3}\n",
        "    return mapping.get(value, 0)  # 0 for any unknown value\n",
        "\n",
        "# Apply the mapping to the Embarked column\n",
        "train_data['Embarked'] = train_data['Embarked'].map(map_embarked)\n",
        "test_data['Embarked'] = test_data['Embarked'].map(map_embarked)\n",
        "\n",
        "# Display the first few rows to verify changes\n",
        "print(\"First few rows of training data with updated Embarked column:\")\n",
        "print(train_data[['PassengerId', 'Embarked']].head())\n",
        "\n",
        "print(\"\\nFirst few rows of test data with updated Embarked column:\")\n",
        "print(test_data[['PassengerId', 'Embarked']].head())\n",
        "\n",
        "# Check the distribution of Embarked values in training data\n",
        "print(\"\\nDistribution of Embarked values in training data:\")\n",
        "print(train_data['Embarked'].value_counts().sort_index())\n",
        "\n",
        "# Check the distribution of Embarked values in test data\n",
        "print(\"\\nDistribution of Embarked values in test data:\")\n",
        "print(test_data['Embarked'].value_counts().sort_index())\n",
        "\n",
        "# Save the updated datasets\n",
        "train_data.to_csv('train_updated.csv', index=False)\n",
        "test_data.to_csv('test_updated.csv', index=False)\n",
        "\n",
        "print(\"\\nUpdated datasets have been saved as 'train_updated.csv' and 'test_updated.csv'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JCUDsRKHjEng",
        "outputId": "9d2e7b95-223e-48da-a63d-bac03a08fcbd"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First few rows of training data with updated Embarked column:\n",
            "   PassengerId  Embarked\n",
            "0            1         1\n",
            "1            2         3\n",
            "2            3         1\n",
            "3            4         1\n",
            "4            5         1\n",
            "\n",
            "First few rows of test data with updated Embarked column:\n",
            "   PassengerId  Embarked\n",
            "0          892         2\n",
            "1          893         1\n",
            "2          894         2\n",
            "3          895         1\n",
            "4          896         1\n",
            "\n",
            "Distribution of Embarked values in training data:\n",
            "Embarked\n",
            "0      2\n",
            "1    644\n",
            "2     77\n",
            "3    168\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Distribution of Embarked values in test data:\n",
            "Embarked\n",
            "1    270\n",
            "2     46\n",
            "3    102\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Updated datasets have been saved as 'train_updated.csv' and 'test_updated.csv'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training models and calculating accuracy"
      ],
      "metadata": {
        "id": "muAG7vs8ohAu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import SVC, LinearSVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import LogisticRegression, Perceptron, SGDClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "# Load the data\n",
        "train_data = pd.read_csv('train_updated.csv')\n",
        "test_data = pd.read_csv('test_updated.csv')\n",
        "\n",
        "# Separate features and target for training data\n",
        "X_train = train_data.drop('Survived', axis=1)\n",
        "Y_train = train_data['Survived']\n",
        "\n",
        "# Prepare test data\n",
        "X_test = test_data.copy()\n",
        "\n",
        "# Scale the features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Define models\n",
        "models = {\n",
        "    'Support Vector Machines': SVC(),\n",
        "    'KNN': KNeighborsClassifier(),\n",
        "    'Logistic Regression': LogisticRegression(),\n",
        "    'Random Forest': RandomForestClassifier(n_estimators=100),\n",
        "    'Naive Bayes': GaussianNB(),\n",
        "    'Perceptron': Perceptron(),\n",
        "    'Stochastic Gradient Descent': SGDClassifier(),\n",
        "    'Linear SVC': LinearSVC(),\n",
        "    'Decision Tree': DecisionTreeClassifier()\n",
        "}\n",
        "\n",
        "# Train models and calculate accuracy\n",
        "accuracies = {}\n",
        "for name, model in models.items():\n",
        "    model.fit(X_train_scaled, Y_train)\n",
        "    acc = round(model.score(X_train_scaled, Y_train) * 100, 2)\n",
        "    accuracies[name] = acc\n",
        "\n",
        "# Sort accuracies from largest to smallest\n",
        "sorted_accuracies = dict(sorted(accuracies.items(), key=lambda item: item[1], reverse=True))\n",
        "\n",
        "# Print sorted accuracies\n",
        "print(\"\\nModel Accuracies (sorted from largest to smallest):\")\n",
        "for model, accuracy in sorted_accuracies.items():\n",
        "    print(f\"{model}: {accuracy}%\")\n",
        "\n",
        "# Optional: Make predictions with the best model (assuming Random Forest is best)\n",
        "best_model = models['Random Forest']\n",
        "Y_pred = best_model.predict(X_test_scaled)\n",
        "\n",
        "# Create submission file\n",
        "submission = pd.DataFrame({\n",
        "    'PassengerId': test_data['PassengerId'],\n",
        "    'Survived': Y_pred\n",
        "})\n",
        "submission.to_csv('submission.csv', index=False)\n",
        "print(\"\\nPredictions saved to 'submission.csv'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VVnEAsuCmhxW",
        "outputId": "7429b52a-3732-4b3a-e2b7-2dd539ae023a"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Model Accuracies (sorted from largest to smallest):\n",
            "Random Forest: 100.0%\n",
            "Decision Tree: 100.0%\n",
            "KNN: 85.86%\n",
            "Support Vector Machines: 83.73%\n",
            "Logistic Regression: 80.7%\n",
            "Naive Bayes: 80.58%\n",
            "Linear SVC: 80.36%\n",
            "Stochastic Gradient Descent: 80.13%\n",
            "Perceptron: 79.35%\n",
            "\n",
            "Predictions saved to 'submission.csv'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    }
  ]
}